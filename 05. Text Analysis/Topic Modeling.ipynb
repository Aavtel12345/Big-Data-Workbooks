{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "## Topic Modeling Using MALLET <a id='table'></a>\n",
    "For this exercise, we will be using data contained in the \"homework\" database on the Big Data for Social Science Class Server. This notebook will walk you through topic modeling NIH abstracts using [MALLET.](#http://mallet.cs.umass.edu/topics.php)\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [Initialization](#Initialization)\n",
    "- [Getting Data](#Getting-Data)\n",
    "\n",
    "    - [Exercise 1](#Exercise-1)\n",
    "\n",
    "- [Generating Topics](#Generating-Topics)\n",
    "\n",
    "    - [Exercise 2](#Exercise-2)\n",
    "    - [Exercise 3](#Exercise-3)\n",
    "\n",
    "- [Inferring Topics](#Inferring_Topics)\n",
    "\n",
    "    - [Exercise 4](#Exercise-4)\n",
    "\n",
    "- [Resources](#resources)\n",
    "\n",
    "## Initialization\n",
    "\n",
    "Before we begin, we'll need to run the following code cells, one of which imports Python libraries we'll be using, and one which defines a function, `terminal()`, that we'll use to run commands on the server.  Please run the following code cell before proceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing the modules we will use in this workbook\n",
    "from subprocess import Popen, PIPE\n",
    "import os\n",
    "import MySQLdb\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# download punkt tokenizers\n",
    "nltk.download( \"punkt\" )\n",
    "nltk.download( \"stopwords\" )\n",
    "\n",
    "# and, defining our terminal() function\n",
    "def terminal(args):\n",
    "    pipe = Popen(args, stdout = PIPE, stderr=PIPE)\n",
    "    text, err = pipe.communicate()    \n",
    "    text = text.decode()\n",
    "    err = err.decode()\n",
    "    if len(text) > 2:\n",
    "        return text\n",
    "    elif len(err) > 2:\n",
    "        return err\n",
    "    else:\n",
    "        print(\"No output returned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data\n",
    "\n",
    "* Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "We will be using a sample of abstracts from NIH grants stored in the 'TextAnalysis' table in the 'homework' database to explore automated text analysis.\n",
    "\n",
    "This table was created by taking a sample of abstracts from the grants located in the broader 'umetricsgrants' database.\n",
    "\n",
    "For text analysis, we'll be automatically deriving a list of topics based on these abstracts using MALLET, a Java based text analysis tool that makes topic modeling very easy.  MALLET is primarily a command line tool and requires a specific format for its data.  We'll use our `terminal()` function to run it, and we'll be creating appropriately formatted text files for each abstract as part of this exercise.  You can read more about importing data into MALLET [on the MALLET web site's \"Importing Data\" page.](http://mallet.cs.umass.edu/import.php)\n",
    "\n",
    "Let us first create a temporary directory in our home folder using the `terminal()` function.\n",
    "\n",
    "A brief explanation of how the `terminal()` function works: Python can send commands to the terminal using \"subprocess\" so that you never have to leave the iPython notebook.  For your convenience, a `terminal()` function is defined above that implements this for you. It takes in a list of arguments where the first is the name of the command you want to run and subsequent items are the arguments you want to pass to that command.  It returns the output from executing the command. \n",
    "\n",
    "The following `terminal()` call will make a temporary directory named \"`temp`\" in your current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "terminal(['mkdir', 'temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets retrieve the abstracts, their ids, and store each abstract in a file with the id as the filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create MySQL connection\n",
    "user = \"jmorgan\"\n",
    "password = \"hUDpr7TUpbhpsoQfw$cTWbyBb2WCvsgE\"\n",
    "database = \"homework\"\n",
    "\n",
    "# invoke the connect() function, passing parameters in variables.\n",
    "db = MySQLdb.connect( user = user, passwd = password, db = database )\n",
    "\n",
    "# output basic database connection info.\n",
    "print( db )\n",
    "\n",
    "# create a database cursor.\n",
    "cursor = db.cursor( MySQLdb.cursors.DictCursor )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll set up a few functions that we'll use in this exercise.  The first is `writeFile()`, a function that takes in a filename and text, and creates a new file populated with the text.  Run the cell below to define `writeFile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeFile(filename, data):\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        \n",
    "        f.write(str(data))\n",
    "        \n",
    "    #-- END with (automatically closes file) --#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wrote a function to do some initial cleaning of the abstract text - `cleanAbstract()`. This function:\n",
    "\n",
    "- accepts an abstract's text\n",
    "- removes words that would be very common in NIH abstracts, because we dont want them to bias the results\n",
    "- removes stopwords (MALLET can also do that)\n",
    "- removes punctuation\n",
    "- returns the resulting cleaned string\n",
    "\n",
    "Run the cell below to define `cleanAbstract()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanAbstract(text):\n",
    "    \n",
    "    # common words to remove\n",
    "    commonWords = ['study', 'project', 'experiment', 'abstract', 'description', 'studies', \\\n",
    "                  'abstracts', 'projects', 'experiments', 'descriptions']\n",
    "\n",
    "    # remove white space.\n",
    "    text = re.sub('[\\n\\t\\r\\f]+', '', text)\n",
    "    \n",
    "    # convert to all lower case.\n",
    "    text = text.lower()\n",
    "    \n",
    "    # break text up into tokens (words)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # retrieve list of stop words.\n",
    "    stop = stopwords.words('english')\n",
    "\n",
    "    # remove stop words from list of tokens.\n",
    "    tokens = [t for t in tokens if t not in stop]\n",
    "\n",
    "    # remove punctuation from tokens\n",
    "    exclude = set(string.punctuation)\n",
    "    tokenNew=[]\n",
    "    for s in tokens:\n",
    "        snew = ''.join(ch for ch in s if ch not in exclude)\n",
    "        if snew!=\"\":\n",
    "            tokenNew.append(snew)\n",
    "\n",
    "    # remove common words\n",
    "    tokenNew = [t for t in tokenNew if t not in commonWords]\n",
    "\n",
    "    # tie tokens back together.\n",
    "    abstract  = ' '.join(t for t in tokenNew)\n",
    "\n",
    "    return abstract\n",
    "\n",
    "#-- END function cleanAbstract() --#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "* Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Retrieve the abstracts one by one from the database and write them to text files in the temp directory. For your convenience, the writeFile() function has already been created. You just need to call it with the path where you want the file stored and the contents of the abstract.\n",
    "\n",
    "When writing files, write each to the `temp` directory we created inside the current directory (path is \"./temp\").  Set the name of the files to the application ID from their grant (stored in the \"`APPLICATION_ID`\" column in the `TextAnalysis` database table), followed by \".txt\".\n",
    "\n",
    "So, the path for a given file should be:\n",
    "\n",
    "    ./temp/<application_id>.txt\n",
    "    \n",
    "The text of each abstract is stored in the \"`ABSTRACT_TEXT`\" column in the `TextAnalysis` table.  Make sure to clean the text using `cleanAbstract()` before you write it out to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "TA_1",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# First create the query that you need to get the abstracts\n",
    "query = 'SELECT * FROM TextAnalysis where TextAnalysis.ABSTRACT_TEXT LIMIT 1000;'\n",
    "\n",
    "#Execute the query\n",
    "cursor.execute(query)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "#Fetch the results one by one and write them to a file\n",
    "row = cursor.fetchone()\n",
    "while (row is not None):\n",
    "    ID = row['APPLICATION_ID']\n",
    "    abstract = row['ABSTRACT_TEXT']\n",
    "    abstract = cleanAbstract(abstract)\n",
    "    filename = './temp/' + str(ID) + \".txt\"\n",
    "    writeFile(filename, abstract)\n",
    "    row = cursor.fetchone()\n",
    "### END SOLUTION\n",
    "\n",
    "# clean up\n",
    "cursor.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "TA_1_Test1",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test to see if file was successfully written\n",
    "f = open('./temp/6187933.txt', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Topics\n",
    "\n",
    "* Back to the [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now created a number of .txt files in the temp directory, each of which contains a single abstract.  We will be using the set of these abstracts together as a corpus of data for machine learning.\n",
    "\n",
    "Our next task is to transform these individual files into a single file in MALLET format. To achieve this, we will use MALLET's import command. The import command can read in an entire directory, turn it into a MALLET file, and can also strip out common english stopwords. Our command will look something like this:\n",
    "\n",
    "    /bin/mallet/bin/mallet import-dir --input path/to/temp/directory --output data.mallet --keep-sequence --remove-stopwords\n",
    "\n",
    "Lets break down this command into each of the separate tokens it contains (where tokens are words separated by spaces):\n",
    "\n",
    "- **`/bin/mallet/bin/mallet`** ==> is the path to the MALLET program\n",
    "- **`import-dir`** ==> the first argument to the program mallet specifies what command the program is being asked to do.  The `import-dir` command tells MALLET to import an entire directory of files into a MALLET data file.\n",
    "- **`--input`** ==> \"--\" are used in MALLET to signify parameter names, usually followed by a space and a parameter value.  `--input` is a parameter used to tell MALLET the directory in which the corpus of data is located.\n",
    "- **`/path/to/temp/directory`** ==> Path to the directory that contains the corpus of data (the value for the parameter `--input`).\n",
    "- **`--output`** ==> tells MALLET where to store the output\n",
    "- **`data.mallet`** ==> name of file we'll store the MALLET data in (the value for the parameter `--outout`).\n",
    "- **`--keep-sequence`** ==> parameter that tells MALLET to keep the original texts in the order in which they were listed in the directory.  This is an example of a parameter that doesn't have an associated value.\n",
    "- **`--remove-stopwords`** ==> parameter that tells MALLET to remove common english stopwords like \"a\", \"an\", and \"the\".  Another parameter with no subsequent value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "* Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Now use the terminal() function to run the MALLET import-dir command on your \"./temp\" directory.  Remember, the `terminal()` function accepts a list of arguments, with the command to be run the first item in the list, and then subsequent details of the command after, with each space-delimited part of the command an item in this list.  Given the above breakdown of the `import-dir` command, break that command into a list of arguments and invoke the command using `terminal()`, reading from your \"./temp\" directory and outputting the resulting MALLET data file to \"data.mallet\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "TA_2",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# store argument list in args[]\n",
    "args = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "args  = ['/bin/mallet/bin/mallet', 'import-dir', '--input',  './temp', '--output', \\\n",
    "         'data.mallet', '--keep-sequence', '--remove-stopwords']\n",
    "### END SOLUTION\n",
    "\n",
    "# run terminal() on args and print out results.\n",
    "print( terminal( args ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "TA_2_Test1",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test to see if file data.mallet was successfully written\n",
    "f = open('./data.mallet', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you go to your working directory now, you should find a file named \"`data.mallet`\".  This is the MALLET data file that we will use as input when we ask MALLET to generate topics based on a corpus of text.\n",
    "\n",
    "We will use the `train-topics` command in MALLET to generate our very own topic models.\n",
    "\n",
    "In the following example, we execute this command using its default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = ['/bin/mallet/bin/mallet', 'train-topics', '--input', 'data.mallet']\n",
    "print(terminal(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command opens `data.mallet` and repeatedly runs MALLET's topic modeling algorithm on the corpus of documents in  it using default settings, printing out the results as it goes and using the results of each run to train a topic detection model to detect topics based on words used in texts in the corpus.  By default, MALLET prints out the top 10 topics every 50th iteration. A good way to judge if the algorithm has converged is to look at the output. Each time it outputs topics, for each of the ten topics, it outputs the topic ID, tIf it stops changing much between iterations, it means that the algorithm has converged.\n",
    "\n",
    "You can read more about the different options that can be used to fine tune the results [on the MALLET web site's \"Topic Modeling\" page.](http://mallet.cs.umass.edu/topics.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "* Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In the above example, we ran the base topic modeling algorithm but we didn't save the output anywhere.  If you look at the documentation pointed to above, it gives you different options to store the output.  Using this documentation as a guide, modify the MALLET command list used to invoke \"`train-topics`\" to output:\n",
    "\n",
    "- topic keys\n",
    "- topic composition of documents\n",
    "- a serialized MALLET topic trainer object\n",
    "\n",
    "Also add the option to:\n",
    "\n",
    "- enable hyperparameter optimization\n",
    "- increase the number of sampling iterations to 20,000\n",
    "- increase the number of topics to 20\n",
    "\n",
    "Store the output of `--output-doc-topics` in a file called `docTopics.txt`.\n",
    "\n",
    "**_NOTE: the topic modeling in this code cell could take a long time to complete - as long as there is an asterisk in the square brackets to its left (\"In [*]\"), it should still be running.  Give it some time._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "TA_3",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#  Modify the MALLET command to output topic keys, topic composition of documents, and a serialized MALLET topic trainer object.\n",
    "# Add the option to enable hyperparameter optimization, increase the number of sampling iterations to 20,000,\n",
    "# and increase the number of topics to 20.\n",
    "\n",
    "# store argument list in args[]\n",
    "args = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "args = ['/bin/mallet/bin/mallet', 'train-topics', '--input', 'data.mallet', '--optimize-interval', '10', \\\n",
    "        '--output-topic-keys', 'topicKeys.txt', '--output-doc-topics', 'docTopics.txt', '--num-topics', '20', \\\n",
    "       '--num-iterations', '20000']\n",
    "### END SOLUTION\n",
    "\n",
    "# run terminal() on args and print out results.\n",
    "print( terminal( args ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "TA_3_Test1",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test to see if file data.mallet was successfully written\n",
    "f = open('./docTopics.txt', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at some results. Your execution of MALLET should have resulted in two output files:\n",
    "\n",
    "- `topicKeys.txt` - a list of the topics detected in the abstracts, along with their weights and the words associated with each.\n",
    "- `docTopics.txt` - for each file in the corpus, lists each of the detected topics and a relavance score that indicates how likely it is that a given abstract relates to that topic.\n",
    "\n",
    "In `topicKeys.txt`, each topic gets a tab-delimited line in the file.  In a given topic's line, the first number is the numeric identifier of the topic (0, 1, 2, etc.), the second number gives an indication of the weight of that topic, and then after a tab, the line is completed with a list of the keywords associated with that topic.  An example (topic 0, weight 0.01502):\n",
    "\n",
    "    14\t0.05863\thealth care cancer data risk patients individuals outcomes genetic disease women testing aging older unreadable lung effects participants intervention community \n",
    "\n",
    "In `docTopics.txt`, each abstract, represented by its file path in the original directory, has a line in the file that lists the topics associated with that article and a relevance score for each topic, in order of decreasing relevance.  The relevance score runs from 0 to 1, where 0 is not at all relevant and 1 is perfectly related.  Example:\n",
    "\n",
    "    1\tfile:/home/jmorgan/nbgrader/courses/2015-fall-big_data/source/05.%20Text%20Analysis/./temp/6287560.txt\t14\t0.7923786992036733\t16\t0.10258021829417482\t11\t0.0414781353290313\t12\t0.04106461349323023\t17\t0.020602274154395795\t1\t3.1281525697325206E-4\t7\t2.5520223298362594E-4\t15\t2.0605374283754973E-4\t2\t1.4476870589053855E-4\t18\t1.3480683006926762E-4\t6\t1.216816985277047E-4\t10\t1.0585995154023939E-4\t9\t1.0155273496603757E-4\t5\t9.406085778593105E-5\t3\t8.487431366553085E-5\t19\t7.761498905199808E-5\t0\t7.675511604129449E-5\t13\t7.071872110668556E-5\t4\t5.972207592082584E-5\t8\t4.957229813413215E-5\n",
    "\n",
    "In this example, the abstract with ID 6287560 (found in the file path) is most highly related to topic 14 (our example above) with 0.792... relevance score.  In aggregate, this output could help you to find connections between documents based on these detected topics that you might not have otherwise noticed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring Topics\n",
    "\n",
    "* Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "You can use your newly trained model to infer topics for unseen documents. Since we got the first 1000 abstracts to train the model, let us use the model to infer topics on the 1001th abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor.execute('SELECT * FROM TextAnalysis LIMIT 1 OFFSET 1000')\n",
    "data = cursor.fetchone()\n",
    "\n",
    "#Creating a new inference directory\n",
    "terminal(['mkdir', 'infer'])\n",
    "writeFile('./infer/' + str(data[\"APPLICATION_ID\"]) +\".txt\", data[\"ABSTRACT_TEXT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation for topic inference can be found [here](http://mallet.cs.umass.edu/topics.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "* Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Use the MALLET documentation to set up a call to `mallet` to infer topics for the file we just created in the `./infer` folder:\n",
    "\n",
    "- First, we provide a mallet command that will re-run our topic model with an additional parameter to output a topic inference model specification to a file named `model.mallet`.\n",
    "- Next, you'll create and run a mallet command that executes the `import-dir` command to  create a new MALLET data file named `one.mallet`, based on your `./infer` directory rather than your `./temp` directory, that will contain the article whose topics you want to infer.  Use the option `--use-pipe-from data.mallet` to specify our original data file as a training file for this corpus.\n",
    "- Finally, you'll create and run a mallet command that executes the `infer-topics` command, running for 10,000 iterations, using `one.mallet` as the input, the model inferencer we created first as the inferencer, and that outputs the topics for the one abstract to a file named `inf-one.txt`.\n",
    "\n",
    "As mentioned in the documenation, make sure that the new data is compatible with your training data. Use the option `--use-pipe-from [MALLET TRAINING FILE]` in the MALLET command import-dir to specify a training file. Store the inference topics for the abstracts in a file called `inf-one.txt`.\n",
    "\n",
    "**_NOTE: Each of the topic modeling steps outlined above that will be implemented in this code cell could take a long time to complete - as long as there is an asterisk in the square brackets to its left (\"In [*]\"), the code in this cell should still be running on the server.  Give it some time._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "TA_4",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# We will first need to rerun our model with the --inferencer-filename option\n",
    "args = ['/bin/mallet/bin/mallet', 'train-topics', '--input', 'data.mallet', '--optimize-interval', '10', \\\n",
    "        '--output-topic-keys', 'topicKeys.txt', '--output-doc-topics', 'docTopics.txt', '--num-topics', '20', \\\n",
    "       '--num-iterations', '20000', '--inferencer-filename', 'model.mallet']\n",
    "print(terminal(args))\n",
    "\n",
    "# Now use import-dir to pull our one file into a mallet data file,\n",
    "#    then use infer-topics to run the model.mallet inferencer on it.\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "args = ['/bin/mallet/bin/mallet', 'import-dir', '--input', './infer', '--output', 'one.mallet', '--use-pipe-from', \\\n",
    "        'data.mallet']\n",
    "print(terminal(args))\n",
    "\n",
    "args = ['/bin/mallet/bin/mallet', 'infer-topics', '--input', 'one.data', '--inferencer', 'model.mallet', \\\n",
    "  '--output-doc-topics', 'inf-one.txt', '--num-iterations', '10000']\n",
    "print(terminal(args))\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "TA_4_Test1",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test to see if file data.mallet was successfully written\n",
    "f = open('./inf-one.txt', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources for Topic Modeling  <a id='resources'></a>\n",
    "\n",
    "* Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Below you will find some tutorials and resources for topic modeling.\n",
    "- [General Introduction to Topic Modeling](https://www.cs.princeton.edu/~blei/papers/Blei2012.pdf)\n",
    "- [Topic Modeling for Humanists](http://www.scottbot.net/HIAL/?p=19113)\n",
    "- [Interpretation of Topic Models](http://www.umiacs.umd.edu/~jbg/docs/nips2009-rtl.pdf)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
