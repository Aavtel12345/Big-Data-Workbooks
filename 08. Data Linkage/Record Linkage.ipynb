{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this lesson we will learn a little about how to use Python for cleaning input data, including using regular expressions, as well as the basic idea behind probabilistic record linkage. These two topics fit together naturally, because data cleaning can have a signficant impact on the success of record linkage. Being able to compare fields that were normalized the same way will give better results.\n",
    "\n",
    "We will use two data sets for the exercises in this chapter. The first will be a list of NIH projects and researchers pulled from the class database. The second is a list of university employees that was scraped from public web sites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Definition\n",
    "\n",
    "Before we begin the task of record linkage, it's important that we understand the variables in our data. In this workbook, we will take a cursory look at some of the values in our data and compute some simple statistics to ensure that the content makes sense. \n",
    "\n",
    "Begin by loading the two data sets into pandas data frames. The first file uses tabs as field separators, and we specify this in the `read_csv` method. The second data set contains a zip code field that pandas will try to interpret as a number by default. To prevent this, we explicity set the numpy dtype (data type) that we want to use for that column. After we load the two data sets, we all the `head` method on the first data set to examine the first few reords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>campus</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>gross</th>\n",
       "      <th>base</th>\n",
       "      <th>overtime</th>\n",
       "      <th>extra</th>\n",
       "      <th>exclude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1751971</td>\n",
       "      <td>2011</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>***********</td>\n",
       "      <td>TUTOR - NON-GSHIP</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1758984</td>\n",
       "      <td>2011</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>***********</td>\n",
       "      <td>TUTOR - NON-GSHIP</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1821585</td>\n",
       "      <td>2011</td>\n",
       "      <td>IRVINE</td>\n",
       "      <td>***********</td>\n",
       "      <td>TUTOR - NON-GSHIP</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1966846</td>\n",
       "      <td>2011</td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>MACKEWICZ , CARL E</td>\n",
       "      <td>STAFF RESEARCH ASSOC III</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1758947</td>\n",
       "      <td>2011</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>***********</td>\n",
       "      <td>READER - NON-GSHIP</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  year         campus                name                     title  \\\n",
       "0  1751971  2011       BERKELEY         ***********         TUTOR - NON-GSHIP   \n",
       "1  1758984  2011       BERKELEY         ***********         TUTOR - NON-GSHIP   \n",
       "2  1821585  2011         IRVINE         ***********         TUTOR - NON-GSHIP   \n",
       "3  1966846  2011  SAN FRANCISCO  MACKEWICZ , CARL E  STAFF RESEARCH ASSOC III   \n",
       "4  1758947  2011       BERKELEY         ***********        READER - NON-GSHIP   \n",
       "\n",
       "   gross  base  overtime  extra  exclude  \n",
       "0   0.49     0         0      0        0  \n",
       "1   0.49     0         0      0        0  \n",
       "2   0.51     0         0      0        0  \n",
       "3   0.62     0         0      0        0  \n",
       "4   0.73     0         0      0        0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# specify that the file uses tabs as separators\n",
    "uc = pd.read_csv(\"ucpay2011.csv\", sep=\"\\t\")\n",
    "\n",
    "# the zip code field should be read as a character string\n",
    "nsf = pd.read_csv(\"nsf_awards_2010-2012.csv\", dtype={\"ZipCode\": np.str})\n",
    "\n",
    "# get the first few records from the UC employee file.\n",
    "uc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some initial thoughts about the data:\n",
    "* The ID field looks like a unique identifier that is specific to the data set. If we thought that we were going to use this identifier to link to other data from the same source, then we might take a loser look to see if the values should be interpreted as numbers or character strings. Ideally, this information would appear in the data documentation.\n",
    "* We should check to make sure that the year field contains valid values.\n",
    "* The campus and title fields look like they should be interpreted as finite categorical variables.\n",
    "* The name field appears to contain some redacted values, probably due to a privacy agreement. We will want to link the subset of valid name fields.\n",
    "\n",
    "Let's perform some quick summaries of the fields in the data. We'll ignore the numeric columns for now, because we won't be using them for linkage, but a thorough data definition process would ensure that these columns are valid as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Distinct years = ', array([2011], dtype=int64))\n",
      "('Distinct campuses = ', array(['BERKELEY', 'IRVINE', 'SAN FRANCISCO', 'LOS ANGELES', 'DANR',\n",
      "       'SANTA BARBARA', 'SANTA CRUZ', 'RIVERSIDE', 'DAVIS', 'MERCED',\n",
      "       'SAN DIEGO', 'UCOP'], dtype=object))\n",
      "('Distinct titles = ', array(['TUTOR - NON-GSHIP', 'STAFF RESEARCH ASSOC III',\n",
      "       'READER - NON-GSHIP', ..., 'ATHLETICS MANAGER 4',\n",
      "       'CHIEF EXEC OFFICER - MED CENTR', 'TREASURER OF THE REGENTS'], dtype=object))\n",
      "('Number of distinct titles = ', 2626)\n",
      "('Total rows = ', 259043)\n",
      "('Rows with valid names = ', 163429)\n"
     ]
    }
   ],
   "source": [
    "# print the distinct values in the year, campus, and title columns\n",
    "print(\"Distinct years = \", uc[\"year\"].unique())\n",
    "print(\"Distinct campuses = \", uc[\"campus\"].unique())\n",
    "print(\"Distinct titles = \", uc[\"title\"].unique())\n",
    "\n",
    "# There are too many titles to display, so let's get the count\n",
    "print(\"Number of distinct titles = \", len(uc[\"title\"].unique()))\n",
    "\n",
    "# Print the total number of rows and the number of rows with valid name values\n",
    "print(\"Total rows = \", len(uc))\n",
    "name = uc[\"name\"]\n",
    "print(\"Rows with valid names = \", len(name[name != \"***********\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll take a look at the second data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardId</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>AwardTitle</th>\n",
       "      <th>AwardEffectiveDate</th>\n",
       "      <th>AwardExpirationDate</th>\n",
       "      <th>Name</th>\n",
       "      <th>CityName</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>PhoneNumber</th>\n",
       "      <th>StreetAddress</th>\n",
       "      <th>CountryName</th>\n",
       "      <th>StateName</th>\n",
       "      <th>StateCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415302</td>\n",
       "      <td>Jeffrey</td>\n",
       "      <td>Kuhn</td>\n",
       "      <td>1/15/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Advanced Technology Solar Telescope (ATST) Con...</td>\n",
       "      <td>1/1/2010</td>\n",
       "      <td>9/30/2015</td>\n",
       "      <td>Association of Universities for Research in As...</td>\n",
       "      <td>Washington</td>\n",
       "      <td>200053929</td>\n",
       "      <td>2024832101</td>\n",
       "      <td>1212 New York Avenue, N.W.,</td>\n",
       "      <td>United States</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415302</td>\n",
       "      <td>Robert</td>\n",
       "      <td>Rosner</td>\n",
       "      <td>1/15/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Advanced Technology Solar Telescope (ATST) Con...</td>\n",
       "      <td>1/1/2010</td>\n",
       "      <td>9/30/2015</td>\n",
       "      <td>Association of Universities for Research in As...</td>\n",
       "      <td>Washington</td>\n",
       "      <td>200053929</td>\n",
       "      <td>2024832101</td>\n",
       "      <td>1212 New York Avenue, N.W.,</td>\n",
       "      <td>United States</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415302</td>\n",
       "      <td>Philip</td>\n",
       "      <td>Goode</td>\n",
       "      <td>1/15/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Advanced Technology Solar Telescope (ATST) Con...</td>\n",
       "      <td>1/1/2010</td>\n",
       "      <td>9/30/2015</td>\n",
       "      <td>Association of Universities for Research in As...</td>\n",
       "      <td>Washington</td>\n",
       "      <td>200053929</td>\n",
       "      <td>2024832101</td>\n",
       "      <td>1212 New York Avenue, N.W.,</td>\n",
       "      <td>United States</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>415302</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Rimmele</td>\n",
       "      <td>3/15/2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Advanced Technology Solar Telescope (ATST) Con...</td>\n",
       "      <td>1/1/2010</td>\n",
       "      <td>9/30/2015</td>\n",
       "      <td>Association of Universities for Research in As...</td>\n",
       "      <td>Washington</td>\n",
       "      <td>200053929</td>\n",
       "      <td>2024832101</td>\n",
       "      <td>1212 New York Avenue, N.W.,</td>\n",
       "      <td>United States</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>415302</td>\n",
       "      <td>Stephen</td>\n",
       "      <td>Keil</td>\n",
       "      <td>1/15/2010</td>\n",
       "      <td>3/15/2012</td>\n",
       "      <td>Advanced Technology Solar Telescope (ATST) Con...</td>\n",
       "      <td>1/1/2010</td>\n",
       "      <td>9/30/2015</td>\n",
       "      <td>Association of Universities for Research in As...</td>\n",
       "      <td>Washington</td>\n",
       "      <td>200053929</td>\n",
       "      <td>2024832101</td>\n",
       "      <td>1212 New York Avenue, N.W.,</td>\n",
       "      <td>United States</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardId FirstName LastName  StartDate    EndDate  \\\n",
       "0   415302   Jeffrey     Kuhn  1/15/2010        NaN   \n",
       "1   415302    Robert   Rosner  1/15/2010        NaN   \n",
       "2   415302    Philip    Goode  1/15/2010        NaN   \n",
       "3   415302    Thomas  Rimmele  3/15/2012        NaN   \n",
       "4   415302   Stephen     Keil  1/15/2010  3/15/2012   \n",
       "\n",
       "                                          AwardTitle AwardEffectiveDate  \\\n",
       "0  Advanced Technology Solar Telescope (ATST) Con...           1/1/2010   \n",
       "1  Advanced Technology Solar Telescope (ATST) Con...           1/1/2010   \n",
       "2  Advanced Technology Solar Telescope (ATST) Con...           1/1/2010   \n",
       "3  Advanced Technology Solar Telescope (ATST) Con...           1/1/2010   \n",
       "4  Advanced Technology Solar Telescope (ATST) Con...           1/1/2010   \n",
       "\n",
       "  AwardExpirationDate                                               Name  \\\n",
       "0           9/30/2015  Association of Universities for Research in As...   \n",
       "1           9/30/2015  Association of Universities for Research in As...   \n",
       "2           9/30/2015  Association of Universities for Research in As...   \n",
       "3           9/30/2015  Association of Universities for Research in As...   \n",
       "4           9/30/2015  Association of Universities for Research in As...   \n",
       "\n",
       "     CityName    ZipCode  PhoneNumber                StreetAddress  \\\n",
       "0  Washington  200053929   2024832101  1212 New York Avenue, N.W.,   \n",
       "1  Washington  200053929   2024832101  1212 New York Avenue, N.W.,   \n",
       "2  Washington  200053929   2024832101  1212 New York Avenue, N.W.,   \n",
       "3  Washington  200053929   2024832101  1212 New York Avenue, N.W.,   \n",
       "4  Washington  200053929   2024832101  1212 New York Avenue, N.W.,   \n",
       "\n",
       "     CountryName             StateName StateCode  \n",
       "0  United States  District of Columbia        DC  \n",
       "1  United States  District of Columbia        DC  \n",
       "2  United States  District of Columbia        DC  \n",
       "3  United States  District of Columbia        DC  \n",
       "4  United States  District of Columbia        DC  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* There are separate fields for first name and last name\n",
    "* The data include researchers from universities throughout the US, not just in the UC system\n",
    "* For UC schools we should be able to create a field corresponding to the campus field in the UC data, but this will require some recoding.\n",
    "\n",
    "In the next two sections we will address some of the data issues that we've identied. Before moving on, we will update the `uc` data set so that it only contains records with valid name fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>campus</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>gross</th>\n",
       "      <th>base</th>\n",
       "      <th>overtime</th>\n",
       "      <th>extra</th>\n",
       "      <th>exclude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1966846</td>\n",
       "      <td>2011</td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>MACKEWICZ , CARL E</td>\n",
       "      <td>STAFF RESEARCH ASSOC III</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1870390</td>\n",
       "      <td>2011</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>ESCUJURI , ERIC JOSEPH</td>\n",
       "      <td>TECHNICIAN, SCENE, SR</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1771936</td>\n",
       "      <td>2011</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>JUNG , WOO YONG</td>\n",
       "      <td>POSTDOC-EMPLOYEE</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1892122</td>\n",
       "      <td>2011</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>SHAPIRO , JORDAN ISAAC</td>\n",
       "      <td>TECHNICIAN, SCENE</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1988359</td>\n",
       "      <td>2011</td>\n",
       "      <td>SANTA BARBARA</td>\n",
       "      <td>CUTLER , CHARLES IAN</td>\n",
       "      <td>LABORATORY ASST I</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  year         campus                    name  \\\n",
       "3   1966846  2011  SAN FRANCISCO      MACKEWICZ , CARL E   \n",
       "6   1870390  2011    LOS ANGELES  ESCUJURI , ERIC JOSEPH   \n",
       "7   1771936  2011       BERKELEY         JUNG , WOO YONG   \n",
       "8   1892122  2011    LOS ANGELES  SHAPIRO , JORDAN ISAAC   \n",
       "12  1988359  2011  SANTA BARBARA    CUTLER , CHARLES IAN   \n",
       "\n",
       "                       title  gross  base  overtime  extra  exclude  \n",
       "3   STAFF RESEARCH ASSOC III   0.62  0.00         0      0        0  \n",
       "6      TECHNICIAN, SCENE, SR   1.14  0.00         0      0        0  \n",
       "7           POSTDOC-EMPLOYEE   1.28  1.28         0      0        0  \n",
       "8          TECHNICIAN, SCENE   1.33  0.00         0      0        0  \n",
       "12         LABORATORY ASST I   1.55  0.00         0      0        0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uc_name = uc[name != \"***********\"]\n",
    "uc_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing\n",
    "\n",
    "Above, we noted that we need to parse the name field in the UC data into first, middle, and last name fields. First, let's see what we can do with the built-in `split` method. By default, the `split` method returns a list of strings obtained by splitting the original string on spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem', 'Ipsum']\n",
      "['carrot', 'cake']\n",
      "['Bogart,', 'Humphrey']\n"
     ]
    }
   ],
   "source": [
    "print(\"Lorem Ipsum\".split())\n",
    "print(\"carrot cake\".split())\n",
    "print(\"Bogart, Humphrey\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `split` treats whitespae as delimiting characters, and multiple consecutive whitespace characters are treated like a single delimiter. We can also pass an argument to `split` to be the delimiter. If we set the delimiter explicitly, then multiple delimiters are not combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi,', 'Mom!']\n",
      "['Hi', '       Mom']\n",
      "['Hi', '', '', 'Mom!']\n"
     ]
    }
   ],
   "source": [
    "print(\"Hi,       Mom!\".split())\n",
    "print(\"Hi,       Mom\".split(\",\"))\n",
    "\n",
    "# in the following example, the result will include the empty strings between the first and second commas\n",
    "# and the second and third commas\n",
    "print(\"Hi,,,Mom!\".split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can map the `split` function over the values in the UC employee `name` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3         [MACKEWICZ, ,, CARL, E]\n",
       "6     [ESCUJURI, ,, ERIC, JOSEPH]\n",
       "7            [JUNG, ,, WOO, YONG]\n",
       "8     [SHAPIRO, ,, JORDAN, ISAAC]\n",
       "12      [CUTLER, ,, CHARLES, IAN]\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uc_name[\"name\"].apply(str.split).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty good! Fortunately for us, the UC data includes a space between the last name and the comma separating it from the first name. This is unusual, but it means that the built-in `split` method is sufficient. We can define functions `getlastname` and `getfirstname` that will call the `split` method and extrac the appropriate values from the resulting list. We won't worry about middle names, because the NSF data doesn't include them.\n",
    "\n",
    "It turns out that all name fields in the `uc_name` data frame contain more than one word, even after filtering out the redacted names. Our `getfirstname` function will have to perform a check to make sure that there is a first name to get.\n",
    "\n",
    "Note that the following code displays a warning which we can safely ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\lib\\site-packages\\ipykernel\\__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Python27\\lib\\site-packages\\ipykernel\\__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MACKEWICZ , CARL E</td>\n",
       "      <td>CARL</td>\n",
       "      <td>MACKEWICZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ESCUJURI , ERIC JOSEPH</td>\n",
       "      <td>ERIC</td>\n",
       "      <td>ESCUJURI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JUNG , WOO YONG</td>\n",
       "      <td>WOO</td>\n",
       "      <td>JUNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SHAPIRO , JORDAN ISAAC</td>\n",
       "      <td>JORDAN</td>\n",
       "      <td>SHAPIRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CUTLER , CHARLES IAN</td>\n",
       "      <td>CHARLES</td>\n",
       "      <td>CUTLER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ANDERSON , MARK CALVIN</td>\n",
       "      <td>MARK</td>\n",
       "      <td>ANDERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PATEL , DEV KAPIL</td>\n",
       "      <td>DEV</td>\n",
       "      <td>PATEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HILDER , JAMIE L</td>\n",
       "      <td>JAMIE</td>\n",
       "      <td>HILDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>WU , YALEI</td>\n",
       "      <td>YALEI</td>\n",
       "      <td>WU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>VALERIO , STEVEN GERARD,JR</td>\n",
       "      <td>STEVEN</td>\n",
       "      <td>VALERIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>BAILEY , GREGORY D</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>BAILEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>CRESPO , NOE CUAUHTEMOC</td>\n",
       "      <td>NOE</td>\n",
       "      <td>CRESPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>RENO , BROOKE</td>\n",
       "      <td>BROOKE</td>\n",
       "      <td>RENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>RUBIO DE LA TOR , ELENA</td>\n",
       "      <td>LA</td>\n",
       "      <td>RUBIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>SMITH , KEN A</td>\n",
       "      <td>KEN</td>\n",
       "      <td>SMITH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name firstname   lastname\n",
       "3           MACKEWICZ , CARL E      CARL  MACKEWICZ\n",
       "6       ESCUJURI , ERIC JOSEPH      ERIC   ESCUJURI\n",
       "7              JUNG , WOO YONG       WOO       JUNG\n",
       "8       SHAPIRO , JORDAN ISAAC    JORDAN    SHAPIRO\n",
       "12        CUTLER , CHARLES IAN   CHARLES     CUTLER\n",
       "15      ANDERSON , MARK CALVIN      MARK   ANDERSON\n",
       "25           PATEL , DEV KAPIL       DEV      PATEL\n",
       "26            HILDER , JAMIE L     JAMIE     HILDER\n",
       "46                  WU , YALEI     YALEI         WU\n",
       "73  VALERIO , STEVEN GERARD,JR    STEVEN    VALERIO\n",
       "74          BAILEY , GREGORY D   GREGORY     BAILEY\n",
       "81     CRESPO , NOE CUAUHTEMOC       NOE     CRESPO\n",
       "83               RENO , BROOKE    BROOKE       RENO\n",
       "91     RUBIO DE LA TOR , ELENA        LA      RUBIO\n",
       "94               SMITH , KEN A       KEN      SMITH"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getfirstname(name):\n",
    "    parts = name.split()\n",
    "    \n",
    "    if len(parts) >= 3:\n",
    "        return parts[2]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def getlastname(name):\n",
    "    parts = name.split()\n",
    "    return parts[0]\n",
    "\n",
    "uc_name[\"firstname\"] = uc_name[\"name\"].apply(getfirstname)\n",
    "uc_name[\"lastname\"] = uc_name[\"name\"].apply(getlastname)\n",
    "\n",
    "# Let's see the result\n",
    "uc_name[[\"name\", \"firstname\", \"lastname\"]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I intentionally showed 15 rows instead of the default 10 so that we could see an example of our simple approach failing. The second to last row in the result contains a last name that comprises several words. Our rule, which extracted the first word to be the \"last name\" does not give the correct result.\n",
    "\n",
    "There is a more subtle problem as well. It's likely that the third name, WOO YONG, should not be split into a first name and middle name component. That is, WOO YONG may in fact be the first name of the referenced individual. This format is common for names from some countries, including China and Korea.\n",
    "\n",
    "Let's redefine the `getfirstname` and `getlastname` functions so that the last name consists of everything before the comma and the first name consists of the first word after the comma. This doesn't solve our problem with Chinese and Korean names, but it's a good start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\lib\\site-packages\\ipykernel\\__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Python27\\lib\\site-packages\\ipykernel\\__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MACKEWICZ , CARL E</td>\n",
       "      <td>CARL</td>\n",
       "      <td>MACKEWICZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ESCUJURI , ERIC JOSEPH</td>\n",
       "      <td>ERIC</td>\n",
       "      <td>ESCUJURI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JUNG , WOO YONG</td>\n",
       "      <td>WOO</td>\n",
       "      <td>JUNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SHAPIRO , JORDAN ISAAC</td>\n",
       "      <td>JORDAN</td>\n",
       "      <td>SHAPIRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CUTLER , CHARLES IAN</td>\n",
       "      <td>CHARLES</td>\n",
       "      <td>CUTLER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ANDERSON , MARK CALVIN</td>\n",
       "      <td>MARK</td>\n",
       "      <td>ANDERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PATEL , DEV KAPIL</td>\n",
       "      <td>DEV</td>\n",
       "      <td>PATEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HILDER , JAMIE L</td>\n",
       "      <td>JAMIE</td>\n",
       "      <td>HILDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>WU , YALEI</td>\n",
       "      <td>YALEI</td>\n",
       "      <td>WU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>VALERIO , STEVEN GERARD,JR</td>\n",
       "      <td>STEVEN</td>\n",
       "      <td>VALERIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>BAILEY , GREGORY D</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>BAILEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>CRESPO , NOE CUAUHTEMOC</td>\n",
       "      <td>NOE</td>\n",
       "      <td>CRESPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>RENO , BROOKE</td>\n",
       "      <td>BROOKE</td>\n",
       "      <td>RENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>RUBIO DE LA TOR , ELENA</td>\n",
       "      <td>ELENA</td>\n",
       "      <td>RUBIO DE LA TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>SMITH , KEN A</td>\n",
       "      <td>KEN</td>\n",
       "      <td>SMITH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name firstname         lastname\n",
       "3           MACKEWICZ , CARL E      CARL        MACKEWICZ\n",
       "6       ESCUJURI , ERIC JOSEPH      ERIC         ESCUJURI\n",
       "7              JUNG , WOO YONG       WOO             JUNG\n",
       "8       SHAPIRO , JORDAN ISAAC    JORDAN          SHAPIRO\n",
       "12        CUTLER , CHARLES IAN   CHARLES           CUTLER\n",
       "15      ANDERSON , MARK CALVIN      MARK         ANDERSON\n",
       "25           PATEL , DEV KAPIL       DEV            PATEL\n",
       "26            HILDER , JAMIE L     JAMIE           HILDER\n",
       "46                  WU , YALEI     YALEI               WU\n",
       "73  VALERIO , STEVEN GERARD,JR    STEVEN          VALERIO\n",
       "74          BAILEY , GREGORY D   GREGORY           BAILEY\n",
       "81     CRESPO , NOE CUAUHTEMOC       NOE           CRESPO\n",
       "83               RENO , BROOKE    BROOKE             RENO\n",
       "91     RUBIO DE LA TOR , ELENA     ELENA  RUBIO DE LA TOR\n",
       "94               SMITH , KEN A       KEN            SMITH"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getfirstname(name):\n",
    "    parts = name.split(\",\")\n",
    "    \n",
    "    if len(parts) > 1:\n",
    "        # The name contains a comma. Take the part after the comma, split on whitespace,\n",
    "        # and grab the first word\n",
    "        return parts[1].split()[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def getlastname(name):\n",
    "    parts = name.split(\",\")\n",
    "    \n",
    "    # Return the first part (everything up to the first comma)\n",
    "    # call the `strip` method to remove the space between the last name and the comma\n",
    "    return parts[0].strip()\n",
    "\n",
    "uc_name[\"firstname\"] = uc_name[\"name\"].apply(getfirstname)\n",
    "uc_name[\"lastname\"] = uc_name[\"name\"].apply(getlastname)\n",
    "\n",
    "# Let's see the result\n",
    "uc_name[[\"name\", \"firstname\", \"lastname\"]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to solve our parsing problem using the `split` method. Sometimes we need a more heavy duty way to search and extract text. In this section we introduce the basics of regular expressions, because they are a common approach to text parsing and a powerful one, too.\n",
    "\n",
    "Regular expressions are a mini-language for searching text. We have already noted that regular expressions are *powerful*, but they can also be *complex*. \n",
    "\n",
    "> Some people, when confronted with a problem, think \"I know, I'll use regular expressions.\" Now they have two problems. \n",
    "\n",
    "> &mdash; Jamie Zawinski\n",
    "\n",
    "In the previous section we were trying to extract first and last names from the UC name field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3         MACKEWICZ , CARL E\n",
       "6     ESCUJURI , ERIC JOSEPH\n",
       "7            JUNG , WOO YONG\n",
       "8     SHAPIRO , JORDAN ISAAC\n",
       "12      CUTLER , CHARLES IAN\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uc_name[\"name\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used basic python functions to try to split the names into first and last name components. In this section we'll use regular expressions to accomplish this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In words, this is how I would explain where to find the last name component in the author field: \"starting from the beginning of the line, take all the characters until you see a comma.\" We can build a regular expression that captures this idea from the following components:\n",
    "* `^` Matches beginning of the line\n",
    "* `.` Matches any character\n",
    "* `+` A modifier that means \"match one or more of the preceding expression\"\n",
    "The comma is not a special character in regular expressions, so it will match itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match at 0x124722a0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = re.search(r\"^.+,\", \"Su, Yu-Wen\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things:\n",
    "* We used \"raw\" string syntax `r\"\"` to prevent python from escaping any special characters that might appear in our regular expression.\n",
    "* If the regular expression matches something in the searched string, then `m` holds a python match-data object. Otherwise, it will be `None`.\n",
    "\n",
    "To see the matched substring, use the `group` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Su,'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is almost what we want, but it would be nice if we weren't also capturing the comma. The problem is that we need the comma in our regular expression in order to know where the last name ends. The solution is to use regular expression groups by putting parentheses around parts of the regular expression that we want to refer to later.\n",
    "* `(...)` Creates a group that can be referred to later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Franklin,\n",
      "Franklin\n"
     ]
    }
   ],
   "source": [
    "m = re.search(r\"^(.*),\", \"Franklin, Benjamin\")\n",
    "\n",
    "print(m.group())\n",
    "print(m.group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a match-data object `m`, `m.group(1)` will show you what was matched by the expression between the first set of parentheses,  `m.group(2)` will show you what was matched by the expression between the second set of parentheses, and so on. `m.group()` is a synonym for `m.group(0)` and it always refers to what was matched by the entire regular expression.\n",
    "\n",
    "Now let's write a regular expression that will match the first name of the employee (that is, the first word after the comma). In addition to the bits of regular expressions we saw above, here are some other useful character classes:\n",
    "* `\\w` Matches a single alphanumeric character\n",
    "* `\\W` Matches anything that is not an alphanumeric character\n",
    "* `\\s` Matches a single whitespace character\n",
    "* `\\S` Matches anything that is not a whitespace character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dwight'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = r\",\\s*(\\w+)\"\n",
    "m = re.search(regex, \"Eisenhower, Dwight David\")\n",
    "m.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions are a powerful tool and we're barely scratching the surface. \n",
    "\n",
    "## References\n",
    "* Python documentation: https://docs.python.org/2/library/re.html#regular-expression-syntax\n",
    "* Online regular expression tester (good for learning): http://regex101.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Comparators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will demonstrate different string comparator algorithms which are provided by the [jellyfish](https://github.com/sunlightlabs/jellyfish) package by writing a function that takes a name as an argument and returns the names in the NSF data that are most similar to the argument. We will start by importing the package and creating a `set` of unique first names from the NSF data. The `FistName` field is missing some values which are represented as NaN in the data frame. To prevent errors later on, we only include valid character strings (which have type `str`) in our list of unique names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jellyfish as jf\n",
    "\n",
    "uniq_first_names = set(name for name in nsf[\"FirstName\"] if type(name) == str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define our function. It should:\n",
    "* Take a name (i.e., a string) as an argument\n",
    "* Optionally, take a number `n` which determines the size of the output\n",
    "* Compare the name to each name in `uniq_first_names` using the Levenshtein distance string comparator\n",
    "* Return a list of the `n` names in `uniq_first_names` that are closest to the argument\n",
    "\n",
    "Here's one implementation. Note that in the comparison we capitalize both names being compared, so that letter case doesn't affect the final distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def closest_names(name, n=10):\n",
    "    # First create a list of tuples (other_name, distance), where\n",
    "    # other_name is taken from uniq_first_names\n",
    "    distances = [(other_name, jf.levenshtein_distance(unicode(name.upper()), unicode(other_name.upper()))) \n",
    "                 for other_name in uniq_first_names]\n",
    "    \n",
    "    # Sort distances by the second element in the tuple, and return the top n values\n",
    "    return sorted(distances, key=lambda x: x[1])[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out on some names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jennifer', 0), ('Jenifer', 1), ('Jennie', 2), ('Jeanine', 3), ('Jeannine', 3), ('Jeannie', 3), ('Jennifer A.', 3), ('Annie', 4), ('Lonnie', 4), ('Werner', 4)]\n",
      "[('Sonya', 0), ('Sonia', 1), ('Sona', 1), ('Sofya', 1), ('Sonja', 1), ('Tonya', 1), ('Sofia', 2), ('Sanja', 2), ('Roya', 2), ('Tony', 2)]\n",
      "[('Hailong', 3), ('Jae Hong', 3), ('Wai Tak', 3), ('Airong', 3), ('Aidong', 3), ('Yitong', 3), ('Weizhong', 3), ('Weidong', 3), ('Weiyong', 3), ('Hairong', 3)]\n"
     ]
    }
   ],
   "source": [
    "print(closest_names(\"Jennifer\"))\n",
    "print(closest_names(\"Sonya\"))\n",
    "print(closest_names(\"Wai Tong\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that Levenshtein distance is a kind of edit distance. Edit distances count the number of edit operations needed to change one word to another, and different edit distances count different edit operations as valid. In the case of Levenshtein distance, the valid edit operations are inserting a letter, deleting a letter, or changing a letter. \n",
    "\n",
    "It would be interesting to compare this output to the output from other string comparators included in the jellyfish package:\n",
    "* Levenshtein distance: edit distance where the valid operations are inserting a letter, deleting a letter, or changing a letter\n",
    "* Levenshtein-Damerau distance: edit distance which includes the same operations as Levenshtein distance but also allows transposing two adjacent letters. This can be useful for finding words with typos.\n",
    "* Jaro-Winkler distance: a fast-to-compute string distance based on common letters between two words\n",
    "\n",
    "Let's update our `closest_names` function so that we can specify the string comparator we want to use. Note that for edit distance smaller numbers indicate closer strings, but for Jaro-Winkler distance larger values indicate closer strings. We will have to add an option to our new function that lets us specify the sort order that determines which strings are close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def closest_names_2(string_comparator, name, reverse_sort=False, n=10):\n",
    "    # First create a list of tuples (other_name, distance), where\n",
    "    # other_name is taken from uniq_first_names\n",
    "    distances = [(other_name, string_comparator(unicode(name.upper()), unicode(other_name.upper())))\n",
    "                 for other_name in uniq_first_names]\n",
    "    \n",
    "    # Sort distances by the second element in the tuple, and return the top n values\n",
    "    return sorted(distances, key=lambda x: x[1], reverse=reverse_sort)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('william', 0), ('William', 0), ('Williams', 1), ('Willa', 2), ('Fillia', 2), ('William J', 2), ('Gillian', 2), ('Lillian', 2), ('J.William', 2), ('Willie', 2)]\n",
      "[('william', 0.9666666666666667), ('William', 0.9666666666666667), ('Williams', 0.9416666666666667), ('William J', 0.9222222222222222), ('J.William', 0.8888888888888888), ('Ilia', 0.8888888888888888), ('Willa', 0.8755555555555556), ('William Rogers', 0.8666666666666668), ('H. William', 0.8666666666666667), ('Willie', 0.8444444444444443)]\n"
     ]
    }
   ],
   "source": [
    "# Try it!\n",
    "print(closest_names_2(jf.damerau_levenshtein_distance, \"William\"))\n",
    "print(closest_names_2(jf.jaro_winkler, \"Wiliam\", reverse_sort=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fellegi-Sunter Record Linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will \"manually\" perform the steps in Fellegi-Sunter record linkage. Our goal is to illustrate the Fellegi-Sunter algorithm by breaking it into bitesize pieces. \n",
    "\n",
    "In our example we will compare first names and last names using Levenshtein distance. In the Fellegi-Sunter algorithm, the result of a field comparison is assumed to follow a multinomial distribution. That means it can only take on finitely many values. Therefore we will define a function that compares to strings and returns the value 2, 1, or 0 to indicate an exact match, a nearly exact match, or anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def fuzzy_string_comparator(s1, s2):\n",
    "    if type(s1) != str or type(s2) != str:\n",
    "        return 0\n",
    "    \n",
    "    dist = jf.jaro_winkler(unicode(s1.upper()), unicode(s2.upper()))\n",
    "    if dist >= 0.92:\n",
    "        return 2\n",
    "    if dist >= 0.85:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "print(fuzzy_string_comparator(\"joshua\", \"joshua\"))\n",
    "print(fuzzy_string_comparator(\"joshua\", \"joshau\"))\n",
    "print(fuzzy_string_comparator(\"joshua\", \"todd\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function compares *fields* in a record. Next, we define a function that compares *records*. My record comparison function assumes that records will have the form of a tuple: (identifier, first name, last name). It returns a length 2 tuple that gives the result of applying our fuzzy string comparator to the first name and to the last name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 0)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "def comparison_vector(rec1, rec2):\n",
    "    \"\"\"rec1 and rec2 have the form (id, first name, last name)\"\"\"\n",
    "    m = fuzzy_string_comparator(rec1[1], rec2[1])\n",
    "    n = fuzzy_string_comparator(rec1[2], rec2[2])\n",
    "    return (m, n)\n",
    "\n",
    "print(comparison_vector((1, \"joshua\", \"tokle\"), (2, \"joshua\", \"smith\")))\n",
    "print(comparison_vector((3, \"joshua\", \"tokle\"), (4, \"josue\", \"tolke\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define m-weights and u-weights. An m-weight is the probability of seeing a particular field comparison outcome given that we are comparing two records that represent the same individual. A u-weight is the probability of seeing a particular field outcome given that we are comparing two records that do *not* represent the same individual. For example, if two records represent the same person, the first and last names should match with high probability (the m-weights for the comparison value 2 should be large). On the other hand, suppose we had month of birth in our data set. The probability that two random individuals will agree on month of birth is about 1/12, so we would assign a u-weight of about 1/12 to this outcome.\n",
    "\n",
    "I'm going to make up some m-weights and u-weights here. In practice you might try to fit these to data or tweak them after seeing preliminary output. I don't claim that these are particularly good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The outer list is length 2, corresponding to the number of fields we're comparing.\n",
    "# Each inner list has length 3, because fuzzy string comparator returns 3 possible values.\n",
    "\n",
    "m_weights = [[0.01, 0.14, 0.85], # m-weights corresponding to first name\n",
    "             [0.01, 0.09, 0.90]] # m-weights corresponding to last name\n",
    "\n",
    "u_weights = [[0.88, 0.10, 0.02], # u-weights corresponding to first name\n",
    "             [0.91, 0.08, 0.01]] # u-weights corresponding to last name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a function that compares two records and returns the match score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.761355430586\n",
      "8.24931374626\n",
      "-8.988196321\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def match_score(rec1, rec2):\n",
    "    m, n = comparison_vector(rec1, rec2)\n",
    "    \n",
    "    # what's the log-probability of seeing this comparison vector if the records are a match?\n",
    "    log_pr_given_match = math.log(m_weights[0][m]) + math.log(m_weights[1][n])\n",
    "    \n",
    "    # what's the log-probability of seeing this comparison vector if the records are a nonmatch?\n",
    "    log_pr_given_nonmatch = math.log(u_weights[0][m]) + math.log(u_weights[1][n])\n",
    "    \n",
    "    # return the log-likelihood-ratio\n",
    "    return log_pr_given_match - log_pr_given_nonmatch\n",
    "\n",
    "print(match_score((1, \"joshua\", \"tokle\"), (2, \"joshua\", \"smith\")))\n",
    "print(match_score((1, \"joshua\", \"tokle\"), (4, \"joshu\", \"tolke\")))\n",
    "print(match_score((1, \"joshua\", \"tokle\"), (7, \"christina\", \"jones\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can try to link UC employees to NSF researchers. We will apply **blocking** to reduce the number of comparisons we perform. In particular, I am only going to compare graduate students whose last name begins with the letter \"H\". I will also limit the NSF researchers to those located in California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "startswith_h = uc_name[\"lastname\"].apply(lambda s: s[0] == \"H\")\n",
    "uc_h = uc_name[startswith_h]\n",
    "\n",
    "startswith_h = nsf[\"LastName\"].apply(lambda s: type(s) == str and s[0].upper() == \"H\")\n",
    "nsf_h = nsf[startswith_h]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The following chunk is time-consuming.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This cell takes a minute to execute\n",
    "\n",
    "potential_matches = []\n",
    "\n",
    "for _, uc_row in uc_h.iterrows():\n",
    "    rec1 = (uc_row[\"ID\"], uc_row[\"firstname\"], uc_row[\"lastname\"])\n",
    "    for nsf_ix, nsf_row in nsf_h.iterrows():\n",
    "        rec2 = (nsf_ix, nsf_row[\"FirstName\"], nsf_row[\"LastName\"])\n",
    "        score = match_score(rec1, rec2)\n",
    "        if score >= 0.5:\n",
    "            potential_matches.append((score, rec1, rec2))\n",
    "            \n",
    "# Sort the output so the best matches appear at the top\n",
    "potential_matches = sorted(potential_matches, key=lambda x: x[0], reverse=True)\n",
    "potential_matches\n",
    "\n",
    "# How did we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
