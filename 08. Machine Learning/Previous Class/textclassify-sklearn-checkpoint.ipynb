{
 "metadata": {
  "name": "",
  "signature": "sha256:11f6dc2437cbcba0ddb23c14ba202cabe43d8e32dd14adde86261754463a7445"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn import metrics\n",
      "from operator import itemgetter\n",
      "from sklearn.metrics import classification_report\n",
      "import csv\n",
      "import os\n",
      "from pandas import *\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "from nltk import NaiveBayesClassifier\n",
      "import nltk.classify\n",
      "from nltk.tokenize import wordpunct_tokenize\n",
      "from nltk.corpus import stopwords\n",
      "from collections import defaultdict\n",
      "import random\n",
      "from sklearn.datasets import load_files\n",
      "from sklearn.datasets import load_files\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn import cross_validation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_subset = load_files('../sectorflat/', encoding='latin-1')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_subset.filenames\n",
      "train_subset.target_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "['basicmaterialssector',\n",
        " 'capitalgoodssector',\n",
        " 'conglomeratesindustry',\n",
        " 'consumercyclicalsector',\n",
        " 'consumernon-cyclicalsector',\n",
        " 'energysector',\n",
        " 'financialsector',\n",
        " 'healthcaresector',\n",
        " 'servicessector',\n",
        " 'technologysector',\n",
        " 'transportationsector',\n",
        " 'utilitiessector']"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
        "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
        "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
        "        vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Turn the text documents into vectors of word frequencies\n",
      "vectorizer = TfidfVectorizer(min_df=5,ngram_range=(1,1))\n",
      "X_train = vectorizer.fit_transform(train_subset.data)\n",
      "y_train = train_subset.target\n",
      "\n",
      "\n",
      "#Simple K-Fold cross validation. 10 folds.\n",
      "cv = cross_validation.KFold(len(train_subset), k=10, indices=False)\n",
      "\n",
      "#iterate through the training and test cross validation segments and\n",
      "#run the classifier on each one, aggregating the results into a list\n",
      "results = []\n",
      "for traincv, testcv in cv:\n",
      " probas = MultinomialNB().fit(train[traincv], target[traincv]).predict_proba(train[testcv])\n",
      " results.append( accuracy(target[testcv], [x[1] for x in probas]) )\n",
      "\n",
      "#print out the mean of the cross-validated results\n",
      "print \"Results: \" + str( np.array(results).mean() )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:240: DeprecationWarning: The parameter k was renamed to n_folds and will be removed in 0.15.\n",
        "  \" removed in 0.15.\", DeprecationWarning)\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "Cannot have number of folds n_folds=10 greaterthan the number of samples: 5.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-16-d1bff6a3ea61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#Simple K-Fold cross validation. 10 folds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#iterate through the training and test cross validation segments and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n, n_folds, indices, shuffle, random_state, k)\u001b[0m\n\u001b[0;32m    315\u001b[0m     def __init__(self, n, n_folds=3, indices=True, shuffle=False,\n\u001b[0;32m    316\u001b[0m                  random_state=None, k=None):\n\u001b[1;32m--> 317\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n, n_folds, indices, k)\u001b[0m\n\u001b[0;32m    253\u001b[0m             raise ValueError(\n\u001b[0;32m    254\u001b[0m                 (\"Cannot have number of folds n_folds={0} greater\"\n\u001b[1;32m--> 255\u001b[1;33m                  \"than the number of samples: {1}.\").format(n_folds, n))\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: Cannot have number of folds n_folds=10 greaterthan the number of samples: 5."
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Turn the text documents into vectors of word frequencies\n",
      "vectorizer = TfidfVectorizer(min_df=2,ngram_range=(1,1))\n",
      "X_train = vectorizer.fit_transform(train_subset.data)\n",
      "y_train = train_subset.target\n",
      "\n",
      "# Fit a classifier on the training set\n",
      "classifier = MultinomialNB().fit(X_train, y_train)\n",
      "print(\"Training score: {0:.1f}%\".format(\n",
      "    classifier.score(X_train, y_train) * 100))\n",
      "\n",
      "# Evaluate the classifier on the testing set\n",
      "X_test = vectorizer.transform(train_subset.data)\n",
      "y_test = train_subset.target\n",
      "print(\"Testing score: {0:.1f}%\".format(\n",
      "    classifier.score(X_test, y_test) * 100))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training score: 36.1%\n",
        "Testing score: 36.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}