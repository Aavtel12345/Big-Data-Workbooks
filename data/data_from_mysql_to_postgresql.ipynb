{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting data from mysql to postgresql using pandas\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "- [Setup](#Setup)\n",
    "\n",
    "    - [Setup - Imports](#Setup---Imports)\n",
    "    - [Setup - Database](#Setup---Database)\n",
    "    - [Setup - Functions](#Setup---Functions)\n",
    "    \n",
    "        - [Setup - Function `column_name_to_lower_case`](#Setup---Function-column_name_to_lower_case)\n",
    "        \n",
    "- [Migrate data from MySQL to PostgreSQL](#Migrate-data-from-MySQL-to-PostgreSQL)\n",
    "        \n",
    "- [TODO](#TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages imported at 2016-11-30 17:29:03.870738\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import datetime\n",
    "import pandas\n",
    "import psycopg2\n",
    "import pymysql\n",
    "import sqlalchemy\n",
    "\n",
    "print( \"packages imported at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Database\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database connections created at 2016-11-30 17:29:24.581078\n"
     ]
    }
   ],
   "source": [
    "# Create SQLAlchemy connections to both MySQL and PostgreSQL\n",
    "\n",
    "# ==> MySQL\n",
    "# set up database credentials\n",
    "mysql_username = \"<username>\"\n",
    "mysql_password = \"<password>\"\n",
    "mysql_host = \"localhost\"\n",
    "mysql_port = \"3306\"\n",
    "mysql_database = \"homework\"\n",
    "mysql_charset = \"utf8\"\n",
    "\n",
    "mysql_host = \"cuspdev.local\"\n",
    "mysql_username = \"jonathanmorgan\"\n",
    "mysql_password = \"today123\"\n",
    "\n",
    "# Create database connection for pandas.\n",
    "sqlalchemy_mysql_db = sqlalchemy.create_engine( \"mysql+pymysql://\" + mysql_username + \":\" + mysql_password + \"@\" + mysql_host + \":\" + mysql_port + \"/\" + mysql_database + \"?charset=\" + mysql_charset )\n",
    "\n",
    "# ==> PostgreSQL\n",
    "\n",
    "# set up database credentials\n",
    "pgsql_username = \"<username>\"\n",
    "pgsql_password = \"<password>\"\n",
    "pgsql_host = \"localhost\"\n",
    "pgsql_port = \"5432\"\n",
    "pgsql_database = \"homework\"\n",
    "pgsql_encoding = \"utf8\"\n",
    "\n",
    "pgsql_host = \"cuspdev.local\"\n",
    "pgsql_username = \"jonathanmorgan\"\n",
    "pgsql_password = \"today123\"\n",
    "\n",
    "# Create database connection for pandas.\n",
    "sqlalchemy_pgsql_db = sqlalchemy.create_engine( \"postgresql+psycopg2://\" + pgsql_username + \":\" + pgsql_password + \"@\" + pgsql_host + \":\" + pgsql_port + \"/\" + pgsql_database + \"?client_encoding=\" + pgsql_encoding )\n",
    "\n",
    "print( \"database connections created at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Functions\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup - Function `column_name_to_lower_case`\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function column_names_to_lower_case() declared at 2016-11-30 17:29:28.351296\n"
     ]
    }
   ],
   "source": [
    "# Postgresql works best when all column and table names are lower case.\n",
    "#     Here is a function to convert all column names in a pandas DataFrame\n",
    "#     to lower case.\n",
    "def column_names_to_lower_case( df_IN ):\n",
    "    \n",
    "    '''\n",
    "    Accepts a pandas DataFrame.  Converts all column names to lower case.\n",
    "        Returns the updated DataFrame, or None if error.\n",
    "    '''\n",
    "    \n",
    "    # return reference\n",
    "    dl_OUT = None\n",
    "    \n",
    "    # declare variables\n",
    "    column_name_list = None\n",
    "    rename_map = None\n",
    "    original_name = \"\"\n",
    "    name_lower = \"\"\n",
    "    \n",
    "    # Make sure we have something passed in.\n",
    "    if ( df_IN is not None ):\n",
    "        \n",
    "        # Create dictionary that maps original column names to that smae name in all lower case.\n",
    "        rename_map = {}\n",
    "        \n",
    "        # get list of column names\n",
    "        column_name_list = list( df_IN.columns )\n",
    "        \n",
    "        # loop over column names\n",
    "        for original_name in column_name_list:\n",
    "            \n",
    "            # convert to all lower case\n",
    "            name_lower = original_name.lower()\n",
    "            \n",
    "            # add to rename map\n",
    "            rename_map[ original_name ] = name_lower\n",
    "        \n",
    "        #-- END loop over column names. --#\n",
    "        \n",
    "        # rename columns in DataFrame\n",
    "        df_IN.rename( columns = rename_map, inplace = True )\n",
    "        \n",
    "        # place DataFrame in return reference.\n",
    "        df_OUT = df_IN\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # nothing passed in.  For shame.\n",
    "        print( \"ERROR - no DataFrame passed in.  Nothing to do.\" )\n",
    "        \n",
    "        df_OUT = None\n",
    "        \n",
    "    #-- END check to see if DataFrame passed in --#\n",
    "    \n",
    "    return df_OUT\n",
    "    \n",
    "#-- END function column_names_to_lower_case() --#\n",
    "\n",
    "print( \"function column_names_to_lower_case() declared at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Migrate data from MySQL to PostgreSQL\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# database name\n",
    "database_name = \"homework\"\n",
    "\n",
    "# make a list of the names of the tables we want to migrate\n",
    "homework_table_list = []\n",
    "homework_table_list.append( \"machine_learning\" )\n",
    "homework_table_list.append( \"nsf_award\" )\n",
    "homework_table_list.append( \"text_analysis\" )\n",
    "homework_table_list.append( \"uc_pay_2011\" )\n",
    "homework_table_list.append( \"ugrant\" )\n",
    "homework_table_list.append( \"vendor\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> starting migration of table machine_learning at 2016-11-30 18:40:05.037373\n",
      "machine_learning column names: ['application_id', 'cfda_code', 'year', 'activity', 'administering_ic', 'arra_funded', 'org_name', 'org_dept', 'topic_id', 'study_section', 'total_cost', 'ed_inst_type']\n",
      "<== migration of table machine_learning completed at 2016-11-30 18:40:28.929735\n",
      "==> starting migration of table nsf_award at 2016-11-30 18:40:28.929809\n",
      "nsf_award column names: ['awardid', 'firstname', 'lastname', 'startdate', 'enddate', 'awardtitle', 'awardeffectivedate', 'awardexpirationdate', 'name', 'cityname', 'zipcode', 'phonenumber', 'streetaddress', 'countryname', 'statename', 'statecode']\n",
      "<== migration of table nsf_award completed at 2016-11-30 18:40:40.296275\n",
      "==> starting migration of table text_analysis at 2016-11-30 18:40:40.296351\n",
      "text_analysis column names: ['application_id', 'abstract_text']\n",
      "<== migration of table text_analysis completed at 2016-11-30 18:45:55.263207\n",
      "==> starting migration of table uc_pay_2011 at 2016-11-30 18:45:55.263329\n",
      "uc_pay_2011 column names: ['id', 'year', 'campus', 'name', 'title', 'gross', 'base', 'overtime', 'extra', 'exclude']\n",
      "<== migration of table uc_pay_2011 completed at 2016-11-30 18:46:52.015074\n",
      "==> starting migration of table ugrant at 2016-11-30 18:46:52.015142\n",
      "ugrant column names: ['award_id', 'topic_id', 'proportion', 'agency', 'topic_text']\n",
      "<== migration of table ugrant completed at 2016-11-30 18:46:52.925764\n",
      "==> starting migration of table vendor at 2016-11-30 18:46:52.925825\n",
      "vendor column names: ['periodstartdate', 'award_id', 'institutionid', 'paymentamount', 'cfda', 'fipscode', 'statecode', 'countycode', 'agency_abbrev', 'agency_text', 'sub_agency_text']\n",
      "<== migration of table vendor completed at 2016-11-30 18:47:13.739344\n"
     ]
    }
   ],
   "source": [
    "# declare variables\n",
    "table_select_string = \"\"\n",
    "table_df = None\n",
    "\n",
    "# for each homework database table, pull it in from MySQL, write it out to PostgreSQL.\n",
    "for table_name in homework_table_list:\n",
    "    \n",
    "    print( \"==> starting migration of table \" + table_name + \" at \" + str( datetime.datetime.now() ) )\n",
    "    \n",
    "    # read the table into pandas from mysql\n",
    "    table_select_string = \"SELECT * FROM \" + database_name + \".\" + table_name + \";\"\n",
    "    table_df = pandas.read_sql( table_select_string, con = sqlalchemy_mysql_db )\n",
    "    \n",
    "    # convert column names to lower case\n",
    "    table_df = column_names_to_lower_case( table_df )\n",
    "    \n",
    "    print( table_name + \" column names: \" + str( list( table_df.columns ) ) )\n",
    "    \n",
    "    # write the table into postgresql.\n",
    "    table_df.to_sql( table_name, con = sqlalchemy_pgsql_db )\n",
    "\n",
    "    print( \"<== migration of table \" + table_name + \" completed at \" + str( datetime.datetime.now() ) )\n",
    "    \n",
    "#-- END loop over tables --#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- machine_learning - convert arra_funded from text to int (\\x01 ==> 1, \\x00 ==> 0).\n",
    "- primary keys\n",
    "\n",
    "    - ugrant - PRIMARY KEY (`award_id`,`topic_id`)\n",
    "    - vendor - PRIMARY KEY (`periodstartdate`,`institutionid`,`paymentamount`,`award_id`)\n",
    "    - make \"index\" unique integer primary key where none exists:\n",
    "    \n",
    "        - machine_learning\n",
    "        - nsf_award\n",
    "        - text_analysis\n",
    "        - uc_pay_2011\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
