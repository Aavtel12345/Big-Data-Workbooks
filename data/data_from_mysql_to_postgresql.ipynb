{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting data from mysql to postgresql using pandas\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "- [Setup](#Setup)\n",
    "\n",
    "    - [Setup - Imports](#Setup---Imports)\n",
    "    - [Setup - Database](#Setup---Database)\n",
    "    \n",
    "        - [Setup - Database - SQLAlchemy](#Setup---Database---SQLAlchemy)\n",
    "    \n",
    "    - [Setup - Functions](#Setup---Functions)\n",
    "    \n",
    "        - [Setup - Function `column_name_to_lower_case`](#Setup---Function-column_name_to_lower_case)\n",
    "        \n",
    "- [Migrate data from MySQL to PostgreSQL](#Migrate-data-from-MySQL-to-PostgreSQL)\n",
    "- [Data cleanup](#Data-cleanup)\n",
    "\n",
    "    - [Cleanup - `machine_learning.arra_funded`](#Cleanup---machine_learning.arra_funded)\n",
    "    - [Cleanup - unique constraints for old multi-part keys](#Cleanup---unique-constraints-for-old-multi-part-keys)\n",
    "\n",
    "- [Create tab-delimited files for each table](#Create-tab-delimited-files-for-each-table)\n",
    "- [TODO](#TODO)\n",
    "- [Finally...](#Finally...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages imported at 2016-12-01 11:26:08.379864\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import datetime\n",
    "import pandas\n",
    "import psycopg2\n",
    "import pymysql\n",
    "import sqlalchemy\n",
    "\n",
    "print( \"packages imported at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Database\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database connection info defined at 2016-12-01 14:16:11.584624\n"
     ]
    }
   ],
   "source": [
    "# Variables to hold connection information\n",
    "\n",
    "# ==> MySQL\n",
    "mysql_username = \"<username>\"\n",
    "mysql_password = \"<password>\"\n",
    "mysql_host = \"localhost\"\n",
    "mysql_port = \"3306\"\n",
    "mysql_database = \"homework\"\n",
    "mysql_charset = \"utf8\"\n",
    "\n",
    "mysql_host = \"cuspdev.local\"\n",
    "mysql_username = \"jonathanmorgan\"\n",
    "mysql_password = \"today123\"\n",
    "\n",
    "# ==> PostgreSQL\n",
    "pgsql_username = \"<username>\"\n",
    "pgsql_password = \"<password>\"\n",
    "pgsql_host = \"localhost\"\n",
    "pgsql_port = \"5432\"\n",
    "pgsql_database = \"homework\"\n",
    "pgsql_encoding = \"utf8\"\n",
    "\n",
    "pgsql_host = \"cuspdev.local\"\n",
    "pgsql_username = \"jonathanmorgan\"\n",
    "pgsql_password = \"today123\"\n",
    "\n",
    "print( \"database connection info defined at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup - Database - SQLAlchemy\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlalchemy database engines created at 2016-12-01 13:58:29.290470\n"
     ]
    }
   ],
   "source": [
    "# Create SQLAlchemy connections to both MySQL and PostgreSQL\n",
    "\n",
    "# declare variables\n",
    "connection_string = \"\"\n",
    "execution_option_dict = None\n",
    "mysql_engine = None\n",
    "pgsql_engine = None\n",
    "\n",
    "# shared execution options\n",
    "execution_option_dict = {}\n",
    "execution_option_dict[ \"stream_results\" ] = True\n",
    "#execution_option_dict[ \"autocommit\" ] = True\n",
    "\n",
    "# ==> MySQL\n",
    "\n",
    "# Create database engine for pandas.\n",
    "connection_string = \"mysql+pymysql://\" + mysql_username + \":\" + mysql_password + \"@\" + mysql_host + \":\" + mysql_port + \"/\" + mysql_database + \"?charset=\" + mysql_charset\n",
    "mysql_engine = sqlalchemy.create_engine( connection_string, execution_options = execution_option_dict )\n",
    "\n",
    "# ==> PostgreSQL\n",
    "\n",
    "# Create database engine for pandas.\n",
    "connection_string = \"postgresql+psycopg2://\" + pgsql_username + \":\" + pgsql_password + \"@\" + pgsql_host + \":\" + pgsql_port + \"/\" + pgsql_database + \"?client_encoding=\" + pgsql_encoding\n",
    "pgsql_engine = sqlalchemy.create_engine( connection_string, execution_options = execution_option_dict )\n",
    "\n",
    "print( \"sqlalchemy database engines created at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup - Database - psycopg2\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Create connection and cursor for things that break SQLAlchemy (sigh)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psycopg2 database connection created at 2016-12-01 14:26:44.650466\n"
     ]
    }
   ],
   "source": [
    "# create psycopg2 connection to PostgreSQL using connection variables defined above.\n",
    "pgsql_connection = psycopg2.connect( host = pgsql_host, port = pgsql_port, database = pgsql_database, user = pgsql_username, password = pgsql_password )\n",
    "\n",
    "print( \"psycopg2 database connection created at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psycopg2 database cursor created at 2016-12-01 14:26:46.303424\n"
     ]
    }
   ],
   "source": [
    "# create psycopg2 cursor using pgsql_connection.\n",
    "pgsql_cursor = pgsql_connection.cursor( cursor_factory = psycopg2.extras.DictCursor )\n",
    "\n",
    "print( \"psycopg2 database cursor created at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Functions\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Run the file `data_functions.py`, which contains re-usable database functions.  List of functions will be printed in the output after you execute the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function column_names_to_lower_case() declared at 2016-12-01 14:21:58.253367\n"
     ]
    }
   ],
   "source": [
    "# Must be run in the /data folder.\n",
    "%run data_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Migrate data from MySQL to PostgreSQL\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# database name\n",
    "database_name = \"homework\"\n",
    "\n",
    "# make a list of the names of the tables we want to migrate\n",
    "homework_table_list = []\n",
    "homework_table_list.append( \"machine_learning\" )\n",
    "homework_table_list.append( \"nsf_award\" )\n",
    "homework_table_list.append( \"text_analysis\" )\n",
    "homework_table_list.append( \"uc_pay_2011\" )\n",
    "homework_table_list.append( \"ugrant\" )\n",
    "homework_table_list.append( \"vendor\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> starting migration of table machine_learning at 2016-11-30 18:40:05.037373\n",
      "machine_learning column names: ['application_id', 'cfda_code', 'year', 'activity', 'administering_ic', 'arra_funded', 'org_name', 'org_dept', 'topic_id', 'study_section', 'total_cost', 'ed_inst_type']\n",
      "<== migration of table machine_learning completed at 2016-11-30 18:40:28.929735\n",
      "==> starting migration of table nsf_award at 2016-11-30 18:40:28.929809\n",
      "nsf_award column names: ['awardid', 'firstname', 'lastname', 'startdate', 'enddate', 'awardtitle', 'awardeffectivedate', 'awardexpirationdate', 'name', 'cityname', 'zipcode', 'phonenumber', 'streetaddress', 'countryname', 'statename', 'statecode']\n",
      "<== migration of table nsf_award completed at 2016-11-30 18:40:40.296275\n",
      "==> starting migration of table text_analysis at 2016-11-30 18:40:40.296351\n",
      "text_analysis column names: ['application_id', 'abstract_text']\n",
      "<== migration of table text_analysis completed at 2016-11-30 18:45:55.263207\n",
      "==> starting migration of table uc_pay_2011 at 2016-11-30 18:45:55.263329\n",
      "uc_pay_2011 column names: ['id', 'year', 'campus', 'name', 'title', 'gross', 'base', 'overtime', 'extra', 'exclude']\n",
      "<== migration of table uc_pay_2011 completed at 2016-11-30 18:46:52.015074\n",
      "==> starting migration of table ugrant at 2016-11-30 18:46:52.015142\n",
      "ugrant column names: ['award_id', 'topic_id', 'proportion', 'agency', 'topic_text']\n",
      "<== migration of table ugrant completed at 2016-11-30 18:46:52.925764\n",
      "==> starting migration of table vendor at 2016-11-30 18:46:52.925825\n",
      "vendor column names: ['periodstartdate', 'award_id', 'institutionid', 'paymentamount', 'cfda', 'fipscode', 'statecode', 'countycode', 'agency_abbrev', 'agency_text', 'sub_agency_text']\n",
      "<== migration of table vendor completed at 2016-11-30 18:47:13.739344\n"
     ]
    }
   ],
   "source": [
    "# declare variables\n",
    "table_select_string = \"\"\n",
    "table_df = None\n",
    "\n",
    "# for each homework database table, pull it in from MySQL, write it out to PostgreSQL.\n",
    "for table_name in homework_table_list:\n",
    "    \n",
    "    print( \"==> starting migration of table \" + table_name + \" at \" + str( datetime.datetime.now() ) )\n",
    "    \n",
    "    # read the table into pandas from mysql\n",
    "    table_select_string = \"SELECT * FROM \" + database_name + \".\" + table_name + \";\"\n",
    "    table_df = pandas.read_sql( table_select_string, con = mysql_engine )\n",
    "    \n",
    "    # convert column names to lower case\n",
    "    table_df = column_names_to_lower_case( table_df )\n",
    "    \n",
    "    print( table_name + \" column names: \" + str( list( table_df.columns ) ) )\n",
    "    \n",
    "    # write the table into postgresql.\n",
    "    table_df.to_sql( table_name, con = pgsql_engine )\n",
    "\n",
    "    print( \"<== migration of table \" + table_name + \" completed at \" + str( datetime.datetime.now() ) )\n",
    "    \n",
    "#-- END loop over tables --#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleanup\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup - `machine_learning.arra_funded`\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In the `machine_learning`, table, convert arra_funded from text to int (\\x01 ==> 1, \\x00 ==> 0).  In the MySQL table, the data field is \"bit\" (boolean), and pandas doesn't know what to do with that, so it converts to a string with an explicitly decimal integer value.  Interesting.  Wonder what the format's underlying storage format is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\x00\n",
      "\\x01\n"
     ]
    }
   ],
   "source": [
    "# get distinct values\n",
    "sql_string = \"SELECT DISTINCT arra_funded AS unique_value FROM machine_learning;\"\n",
    "\n",
    "# run SQL.\n",
    "pgsql_cursor.execute( sql_string )\n",
    "\n",
    "# loop over results\n",
    "for current_row in pgsql_cursor:\n",
    "    \n",
    "    # output unique_value\n",
    "    print( str( current_row[ \"unique_value\" ] ) )\n",
    "    \n",
    "#-- END loop over distinct values in arra_funded --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-01 14:56:06.431710: ALTER TABLE public.machine_learning ADD COLUMN arra_funded_int int2;\n"
     ]
    }
   ],
   "source": [
    "# First, make new column `arra_funded_int` that is of type \"int\".\n",
    "sql_string = \"ALTER TABLE public.machine_learning ADD COLUMN arra_funded_int int2;\"\n",
    "\n",
    "# run and commit.\n",
    "#pgsql_cursor.execute( sql_string )\n",
    "#pgsql_connection.commit()\n",
    "\n",
    "print( str( datetime.datetime.now() ) + \": \" + sql_string )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-01 14:56:18.087807: UPDATE public.machine_learning SET arra_funded_int = 0 WHERE arra_funded = '\\x00';\n"
     ]
    }
   ],
   "source": [
    "# Now, set arra_funded_int to 0 where arra_funded = \"\\x00\"...\n",
    "#     have to escape the back-slash with a back-slash ( \"\\\\\" ).\n",
    "sql_string = \"UPDATE public.machine_learning SET arra_funded_int = 0 WHERE arra_funded = '\\\\x00';\"\n",
    "\n",
    "# run and commit.\n",
    "#pgsql_cursor.execute( sql_string )\n",
    "#pgsql_connection.commit()\n",
    "\n",
    "print( str( datetime.datetime.now() ) + \": \" + sql_string )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-01 14:56:27.871735: UPDATE public.machine_learning SET arra_funded_int = 1 WHERE arra_funded = '\\x01';\n"
     ]
    }
   ],
   "source": [
    "# ...and set arra_funded_int to 1 where arra_funded = \"\\x01\".\n",
    "#     have to escape the back-slash with a back-slash ( \"\\\\\" ).\n",
    "sql_string = \"UPDATE public.machine_learning SET arra_funded_int = 1 WHERE arra_funded = '\\\\x01';\"\n",
    "\n",
    "# run and commit.\n",
    "#pgsql_cursor.execute( sql_string )\n",
    "#pgsql_connection.commit()\n",
    "\n",
    "print( str( datetime.datetime.now() ) + \": \" + sql_string )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-01 14:56:34.135046: ALTER TABLE public.machine_learning DROP COLUMN arra_funded;\n"
     ]
    }
   ],
   "source": [
    "# remove arra_funded column\n",
    "sql_string = \"ALTER TABLE public.machine_learning DROP COLUMN arra_funded;\"\n",
    "\n",
    "# run and commit.\n",
    "#pgsql_cursor.execute( sql_string )\n",
    "#pgsql_connection.commit()\n",
    "\n",
    "print( str( datetime.datetime.now() ) + \": \" + sql_string )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-01 14:56:40.826528: ALTER TABLE machine_learning RENAME COLUMN arra_funded_int TO arra_funded;\n"
     ]
    }
   ],
   "source": [
    "# and rename \"arra_funded_int\" to \"arra_funded\"\n",
    "sql_string = \"ALTER TABLE machine_learning RENAME COLUMN arra_funded_int TO arra_funded;\"\n",
    "\n",
    "# run and commit.\n",
    "#pgsql_cursor.execute( sql_string )\n",
    "#pgsql_connection.commit()\n",
    "\n",
    "print( str( datetime.datetime.now() ) + \": \" + sql_string )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup - unique constraints for old multi-part keys\n",
    "\n",
    "- return to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Convert the old primary keys on `ugrants` and `vendor` to just be unique constraints (since we have a unique integer primary key):\n",
    "\n",
    "- ugrant\n",
    "\n",
    "        PRIMARY KEY (`award_id`,`topic_id`)\n",
    "\n",
    "- vendor\n",
    "\n",
    "        PRIMARY KEY (`periodstartdate`,`institutionid`,`paymentamount`,`award_id`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-01 14:56:57.451560: ALTER TABLE ugrant ADD CONSTRAINT ugrant_primary_key UNIQUE( award_id, topic_id );\n"
     ]
    }
   ],
   "source": [
    "# ==> ugrant\n",
    "\n",
    "# create SQL string\n",
    "sql_string = \"ALTER TABLE ugrant ADD CONSTRAINT ugrant_primary_key UNIQUE( award_id, topic_id );\"\n",
    "\n",
    "# run and commit.\n",
    "#pgsql_cursor.execute( sql_string )\n",
    "#pgsql_connection.commit()\n",
    "\n",
    "print( str( datetime.datetime.now() ) + \": \" + sql_string )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-01 14:57:03.358691: ALTER TABLE vendor ADD CONSTRAINT vendor_primary_key UNIQUE( periodstartdate, institutionid, paymentamount, award_id );\n"
     ]
    }
   ],
   "source": [
    "# ==> vendor\n",
    "\n",
    "# create SQL string\n",
    "sql_string = \"ALTER TABLE vendor ADD CONSTRAINT vendor_primary_key UNIQUE( periodstartdate, institutionid, paymentamount, award_id );\"\n",
    "\n",
    "# run and commit.\n",
    "#pgsql_cursor.execute( sql_string )\n",
    "#pgsql_connection.commit()\n",
    "\n",
    "print( str( datetime.datetime.now() ) + \": \" + sql_string )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tab-delimited files for each table\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> starting tab-delimited export of table machine_learning at 2016-12-01 16:13:32.364543\n",
      "<== tab-delimited export of table machine_learning to machine_learning.tab.txt completed at 2016-12-01 16:13:33.933228\n",
      "==> starting tab-delimited export of table nsf_award at 2016-12-01 16:13:33.933322\n",
      "<== tab-delimited export of table nsf_award to nsf_award.tab.txt completed at 2016-12-01 16:13:34.823583\n",
      "==> starting tab-delimited export of table text_analysis at 2016-12-01 16:13:34.823662\n",
      "<== tab-delimited export of table text_analysis to text_analysis.tab.txt completed at 2016-12-01 16:14:55.268936\n",
      "==> starting tab-delimited export of table uc_pay_2011 at 2016-12-01 16:14:55.269152\n",
      "<== tab-delimited export of table uc_pay_2011 to uc_pay_2011.tab.txt completed at 2016-12-01 16:14:59.812808\n",
      "==> starting tab-delimited export of table ugrant at 2016-12-01 16:14:59.812940\n",
      "<== tab-delimited export of table ugrant to ugrant.tab.txt completed at 2016-12-01 16:14:59.920544\n",
      "==> starting tab-delimited export of table vendor at 2016-12-01 16:14:59.920585\n",
      "<== tab-delimited export of table vendor to vendor.tab.txt completed at 2016-12-01 16:15:00.993863\n"
     ]
    }
   ],
   "source": [
    "# declare variables\n",
    "table_select_string = \"\"\n",
    "table_df = None\n",
    "\n",
    "# for each homework database table, pull it in from PostgreSQL, write it out to CSV file.\n",
    "for table_name in homework_table_list:\n",
    "    \n",
    "    print( \"==> starting tab-delimited export of table \" + table_name + \" at \" + str( datetime.datetime.now() ) )\n",
    "    \n",
    "    # read the table into pandas from postgresql\n",
    "    table_select_string = \"SELECT * FROM \" + table_name + \";\"\n",
    "    table_df = pandas.read_sql( table_select_string, con = pgsql_engine )\n",
    "    \n",
    "    # write the table to CSV file.\n",
    "    output_file_path = table_name + \".tab.txt\"\n",
    "    table_df.to_csv( output_file_path, sep = '\\t', encoding = 'utf-8' )\n",
    "\n",
    "    print( \"<== tab-delimited export of table \" + table_name + \" to \" + output_file_path + \" completed at \" + str( datetime.datetime.now() ) )\n",
    "    \n",
    "#-- END loop over tables --#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "TODO:\n",
    "\n",
    "- update notebooks to refer to lower-case names, new table names, and to use the sqlalchemy way of doing SQL calls rather than a direct call via DBAPI.  See if it works for both mysql and postgresql."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally...\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Close engines, connections, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sometimes you'll need to rollback.\n",
    "pgsql_connection.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database connections closed (disposed) at 2016-12-01 13:58:24.887436\n"
     ]
    }
   ],
   "source": [
    "# close SQLAlchemy engines.\n",
    "mysql_engine.dispose()\n",
    "pgsql_engine.dispose()\n",
    "\n",
    "# close psycopg2 DBAPI connection.\n",
    "pgsql_cursor.close()\n",
    "pgsql_connection.close()\n",
    "\n",
    "print( \"database connections closed (disposed) at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
